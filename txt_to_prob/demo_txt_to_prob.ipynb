{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- input: 6 ch EEG (F3, F4, C3, C4, O1, O2) + 2 ch ground (A1, A2)\n",
    "- output: probabilistic hypnogram\n",
    "\n",
    "step1. Load txt  \n",
    "step2. Re-referencing  \n",
    "step3. Create instances of mne.raw  \n",
    "step4. Cropping to make the length of time 5h 30m  \n",
    "step5. Automatic sleep staging using YASA for all six EEG channels  \n",
    "step6. Ensamble and get the probabilistic hypnogram after ensamble  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load subject's ID\n",
      "-- Number of subjects: Healthy(1283), OSA(1933), Insomnia(727), COMISA(785)\n",
      "-- Total: 4728\n",
      "Number of test files: 1499\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import txt_to_prob as tp\n",
    "\n",
    "# 각 class 별, subject ID read\n",
    "print(\"Load subject's ID\")\n",
    "# print('-- Read PSG_list2.xlsx')\n",
    "df_subject_ID = pd.read_csv('D:\\\\USC\\\\code_mine\\\\txt_to_prob\\\\subject_info\\\\PSG_list_by_CYS.csv')\n",
    "\n",
    "pd_healthy = df_subject_ID.iloc[:,0].dropna()\n",
    "pd_OSA = df_subject_ID.iloc[:,1].dropna()\n",
    "pd_INS = df_subject_ID.iloc[:,2].dropna()\n",
    "pd_COMISA = df_subject_ID.iloc[:,3].dropna()\n",
    "\n",
    "pd_total = pd.concat([pd_healthy, pd_OSA, pd_INS, pd_COMISA])\n",
    "print(\"-- Number of subjects: Healthy({}), OSA({}), Insomnia({}), COMISA({})\"\n",
    "      .format(len(pd_healthy), len(pd_OSA), len(pd_INS), len(pd_COMISA)))\n",
    "print(\"-- Total: {}\".format(len(pd_total)))\n",
    "\n",
    "# path_txt = 'E:\\\\samsung_original\\\\ensamble_test' # txt 파일이 저장되어 있는 경로/\n",
    "path_txt = 'E:\\\\samsung_original\\\\whole_data_txt\\\\data1' # txt 파일이 저장되어 있는 경로\n",
    "txt_subjects = pd.Series(os.listdir(path_txt)) # 모든 txt 파일의 filename이 담겨 있는 pd.Series\n",
    "\n",
    "df_SOL = pd.read_csv('subject_info\\\\all_class.csv', index_col=0)\n",
    "\n",
    "print('Number of test files: {}'.format(txt_subjects.size))\n",
    "\n",
    "# 이미 probabilistic hypnogram이 생성된 subject list\n",
    "path_prob_hyp = 'E:\\\\probabilistic_hypnogram'\n",
    "list_hyp_exist = os.listdir(path_prob_hyp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data1 (n=1499) ... :  22%|██▏       | 1042/4728 [00:03<00:12, 296.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- now subject ID : PE190458, number of txt files : 2\n",
      "['PE190458, 김홍길_A1_.txt' 'PE190458, 김홍길_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190554, number of txt files : 2\n",
      "['PE190554, 이영택_A1_.txt' 'PE190554, 이영택_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190602, number of txt files : 2\n",
      "['PE190602, 박찬용_A1_.txt' 'PE190602, 박찬용_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190629, number of txt files : 2\n",
      "['PE190629, 김혜정_A1_.txt' 'PE190629, 김혜정_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190639, number of txt files : 2\n",
      "['PE190639, 임선하_A1_.txt' 'PE190639, 임선하_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190660, number of txt files : 2\n",
      "['PE190660, 박주오_A1_.txt' 'PE190660, 박주오_C4_.txt']\n",
      "Already processed subject ... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data1 (n=1499) ... :  23%|██▎       | 1101/4728 [00:03<00:13, 259.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- now subject ID : PE190696, number of txt files : 2\n",
      "['PE190696, 박준우_A1_.txt' 'PE190696, 박준우_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190723, number of txt files : 2\n",
      "['PE190723, 김민경_A1_.txt' 'PE190723, 김민경_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190731, number of txt files : 2\n",
      "['PE190731, 강영모_A1_.txt' 'PE190731, 강영모_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190732, number of txt files : 2\n",
      "['PE190732, 김빈나_A1_.txt' 'PE190732, 김빈나_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190736, number of txt files : 2\n",
      "['PE190736, 장사현_A1_.txt' 'PE190736, 장사현_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190737, number of txt files : 2\n",
      "['PE190737, 정윤득_A1_.txt' 'PE190737, 정윤득_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190745, number of txt files : 2\n",
      "['PE190745, 박동석_A1_.txt' 'PE190745, 박동석_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190749, number of txt files : 2\n",
      "['PE190749, 이형문_A1_.txt' 'PE190749, 이형문_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190751, number of txt files : 2\n",
      "['PE190751, 고원우_A1_.txt' 'PE190751, 고원우_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190764, number of txt files : 2\n",
      "['PE190764, 박현순_A1_.txt' 'PE190764, 박현순_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190768, number of txt files : 2\n",
      "['PE190768, 남경우_A1_.txt' 'PE190768, 남경우_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190784, number of txt files : 2\n",
      "['PE190784, 이민경_A1_.txt' 'PE190784, 이민경_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190785, number of txt files : 2\n",
      "['PE190785, 전성호_A1_.txt' 'PE190785, 전성호_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190787, number of txt files : 2\n",
      "['PE190787, 김석환_A1_.txt' 'PE190787, 김석환_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190789, number of txt files : 2\n",
      "['PE190789, 정영애_A1_.txt' 'PE190789, 정영애_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190791, number of txt files : 2\n",
      "['PE190791, 정정호_A1_.txt' 'PE190791, 정정호_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190799, number of txt files : 2\n",
      "['PE190799, 유혜경_A1_.txt' 'PE190799, 유혜경_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190803, number of txt files : 2\n",
      "['PE190803, 나종백_A1_.txt' 'PE190803, 나종백_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190808, number of txt files : 2\n",
      "['PE190808, 이상운_A1_.txt' 'PE190808, 이상운_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190811, number of txt files : 2\n",
      "['PE190811, 정영애_A1_.txt' 'PE190811, 정영애_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190817, number of txt files : 2\n",
      "['PE190817, 서민지_A1_.txt' 'PE190817, 서민지_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190820, number of txt files : 2\n",
      "['PE190820, 노숭구_A1_.txt' 'PE190820, 노숭구_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190828, number of txt files : 2\n",
      "['PE190828, 김민성_A1_.txt' 'PE190828, 김민성_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190831, number of txt files : 2\n",
      "['PE190831, 박승호_A1_.txt' 'PE190831, 박승호_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190837, number of txt files : 2\n",
      "['PE190837, 강호하_A1_.txt' 'PE190837, 강호하_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190841, number of txt files : 2\n",
      "['PE190841, 최한슬_A1_.txt' 'PE190841, 최한슬_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190843, number of txt files : 2\n",
      "['PE190843, 이동희_A1_.txt' 'PE190843, 이동희_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190846, number of txt files : 2\n",
      "['PE190846, 조옥선_A1_.txt' 'PE190846, 조옥선_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190853, number of txt files : 2\n",
      "['PE190853, 김산위_A1_.txt' 'PE190853, 김산위_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190855, number of txt files : 2\n",
      "['PE190855, 이상훈_A1_.txt' 'PE190855, 이상훈_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190856, number of txt files : 2\n",
      "['PE190856, 최종규_A1_.txt' 'PE190856, 최종규_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190858, number of txt files : 2\n",
      "['PE190858, 송현길_A1_.txt' 'PE190858, 송현길_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190861, number of txt files : 2\n",
      "['PE190861, 유수종_A1_.txt' 'PE190861, 유수종_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190863, number of txt files : 2\n",
      "['PE190863, 김라은_A1_.txt' 'PE190863, 김라은_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190872, number of txt files : 2\n",
      "['PE190872, 한용희_A1_.txt' 'PE190872, 한용희_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190876, number of txt files : 2\n",
      "['PE190876, 홍준표_A1_.txt' 'PE190876, 홍준표_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190879, number of txt files : 2\n",
      "['PE190879, 오준수_A1_.txt' 'PE190879, 오준수_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190880, number of txt files : 2\n",
      "['PE190880, 최상준_A1_.txt' 'PE190880, 최상준_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190887, number of txt files : 2\n",
      "['PE190887, 이준혁_A1_.txt' 'PE190887, 이준혁_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190896, number of txt files : 2\n",
      "['PE190896, 최경록_A1_.txt' 'PE190896, 최경록_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190900, number of txt files : 2\n",
      "['PE190900, 곽영수_A1_.txt' 'PE190900, 곽영수_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190901, number of txt files : 2\n",
      "['PE190901, 이미자_A1_.txt' 'PE190901, 이미자_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190904, number of txt files : 2\n",
      "['PE190904, 장준수_A1_.txt' 'PE190904, 장준수_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190906, number of txt files : 2\n",
      "['PE190906, 최재순_A1_.txt' 'PE190906, 최재순_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190916, number of txt files : 2\n",
      "['PE190916, 이서윤_A1_.txt' 'PE190916, 이서윤_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190921, number of txt files : 2\n",
      "['PE190921, 문만근_A1_.txt' 'PE190921, 문만근_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190923, number of txt files : 2\n",
      "['PE190923, 박성희_A1_.txt' 'PE190923, 박성희_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190934, number of txt files : 2\n",
      "['PE190934, 윤동성_A1_.txt' 'PE190934, 윤동성_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190935, number of txt files : 2\n",
      "['PE190935, 김규_A1_.txt' 'PE190935, 김규_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190943, number of txt files : 2\n",
      "['PE190943, 김태현_A1_.txt' 'PE190943, 김태현_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190947, number of txt files : 2\n",
      "['PE190947, 박준수_A1_.txt' 'PE190947, 박준수_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190948, number of txt files : 2\n",
      "['PE190948, 전휘수_A1_.txt' 'PE190948, 전휘수_C4_.txt']\n",
      "Already processed subject ... \n",
      "\n",
      "\n",
      "-- now subject ID : PE190949, number of txt files : 2\n",
      "['PE190949, 손희정_A1_.txt' 'PE190949, 손희정_C4_.txt']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data1 (n=1499) ... :  23%|██▎       | 1101/4728 [00:20<00:13, 259.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=2, n_times=4556839\n",
      "    Range : 0 ... 4556838 =      0.000 ... 22784.190 secs\n",
      "Ready.\n",
      "Available channels: ['C4-A1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data1 (n=1499) ... :  24%|██▎       | 1112/4728 [00:40<26:41,  2.26it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- now subject ID : PE190951, number of txt files : 2\n",
      "['PE190951, 송은실_A1_.txt' 'PE190951, 송은실_C4_.txt']\n",
      "Creating RawArray with float64 data, n_channels=2, n_times=5383909\n",
      "    Range : 0 ... 5383908 =      0.000 ... 26919.540 secs\n",
      "Ready.\n",
      "Available channels: ['C4-A1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data1 (n=1499) ... :  24%|██▎       | 1113/4728 [01:05<52:14,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- now subject ID : PE190956, number of txt files : 2\n",
      "['PE190956, 서지영_A1_.txt' 'PE190956, 서지영_C4_.txt']\n",
      "Creating RawArray with float64 data, n_channels=2, n_times=5313109\n",
      "    Range : 0 ... 5313108 =      0.000 ... 26565.540 secs\n",
      "Ready.\n",
      "Available channels: ['C4-A1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data1 (n=1499) ... :  24%|██▎       | 1114/4728 [01:44<1:45:56,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- now subject ID : PE190957, number of txt files : 2\n",
      "['PE190957, 이재민_A1_.txt' 'PE190957, 이재민_C4_.txt']\n",
      "Creating RawArray with float64 data, n_channels=2, n_times=5573609\n",
      "    Range : 0 ... 5573608 =      0.000 ... 27868.040 secs\n",
      "Ready.\n",
      "Available channels: ['C4-A1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data1 (n=1499) ... :  24%|██▎       | 1115/4728 [02:03<2:19:52,  2.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- now subject ID : PE190960, number of txt files : 2\n",
      "['PE190960, 김영희_A1_.txt' 'PE190960, 김영희_C4_.txt']\n",
      "Creating RawArray with float64 data, n_channels=2, n_times=6019089\n",
      "    Range : 0 ... 6019088 =      0.000 ... 30095.440 secs\n",
      "Ready.\n",
      "Available channels: ['C4-A1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data1 (n=1499) ... :  24%|██▎       | 1116/4728 [02:25<3:10:20,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- now subject ID : PE190966, number of txt files : 2\n",
      "['PE190966, 서정자_A1_.txt' 'PE190966, 서정자_C4_.txt']\n",
      "Creating RawArray with float64 data, n_channels=2, n_times=4548869\n",
      "    Range : 0 ... 4548868 =      0.000 ... 22744.340 secs\n",
      "Ready.\n",
      "Available channels: ['C4-A1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data1 (n=1499) ... :  24%|██▎       | 1117/4728 [02:50<4:31:48,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- now subject ID : PE190970, number of txt files : 2\n",
      "['PE190970, 박영자_A1_.txt' 'PE190970, 박영자_C4_.txt']\n",
      "Creating RawArray with float64 data, n_channels=2, n_times=4705739\n",
      "    Range : 0 ... 4705738 =      0.000 ... 23528.690 secs\n",
      "Ready.\n",
      "Available channels: ['C4-A1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data1 (n=1499) ... :  24%|██▎       | 1118/4728 [03:08<5:32:31,  5.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- now subject ID : PE190980, number of txt files : 2\n",
      "['PE190980, 김성훈_A1_.txt' 'PE190980, 김성훈_C4_.txt']\n",
      "Creating RawArray with float64 data, n_channels=2, n_times=5663932\n",
      "    Range : 0 ... 5663931 =      0.000 ... 28319.655 secs\n",
      "Ready.\n",
      "Available channels: ['C4-A1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data1 (n=1499) ... :  24%|██▎       | 1119/4728 [03:28<7:01:16,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- now subject ID : PE190986, number of txt files : 2\n",
      "['PE190986, 황신영_A1_.txt' 'PE190986, 황신영_C4_.txt']\n",
      "Creating RawArray with float64 data, n_channels=2, n_times=5011749\n",
      "    Range : 0 ... 5011748 =      0.000 ... 25058.740 secs\n",
      "Ready.\n",
      "Available channels: ['C4-A1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data1 (n=1499) ... :  24%|██▎       | 1120/4728 [03:56<9:36:24,  9.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- now subject ID : PE190989, number of txt files : 2\n",
      "['PE190989, 안석현_A1_.txt' 'PE190989, 안석현_C4_.txt']\n",
      "Creating RawArray with float64 data, n_channels=2, n_times=4914909\n",
      "    Range : 0 ... 4914908 =      0.000 ... 24574.540 secs\n",
      "Ready.\n",
      "Available channels: ['C4-A1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data1 (n=1499) ... :  24%|██▎       | 1121/4728 [04:13<10:51:50, 10.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- now subject ID : PE190994, number of txt files : 2\n",
      "['PE190994, 황기옥_A1_.txt' 'PE190994, 황기옥_C4_.txt']\n",
      "Creating RawArray with float64 data, n_channels=2, n_times=5696349\n",
      "    Range : 0 ... 5696348 =      0.000 ... 28481.740 secs\n",
      "Ready.\n",
      "Available channels: ['C4-A1']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing data1 (n=1499) ... :  24%|██▎       | 1122/4728 [04:33<12:29:30, 12.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "-- now subject ID : PE191000, number of txt files : 2\n",
      "['PE191000, 김귀영_A1_.txt' 'PE191000, 김귀영_C4_.txt']\n"
     ]
    }
   ],
   "source": [
    "QNAN = []\n",
    "for sub_ID in tqdm(pd_total,desc='Processing data1 (n=1499) ... '):\n",
    "       \n",
    "    # Read txt files and extract eeg data for all channels\n",
    "    txt2np = tp.txt2np(path_txt, txt_subjects, sub_ID)\n",
    "    txt2np.txt_filenames()\n",
    "\n",
    "    if sub_ID in list_hyp_exist:\n",
    "          # 이미 probabilistic hypnogram이 있는 경우, pass !\n",
    "          print('Already processed subject ... ')\n",
    "          continue \n",
    "\n",
    "    if len(txt2np.temp_txt_subjects) < 2:\n",
    "          continue\n",
    "    np_all_eeg = txt2np.read_txt()\n",
    "    QNAN.append(txt2np.QNAN_dic)\n",
    "    # Create mne.raw instance \n",
    "    # - data: np_all_eeg\n",
    "    # - raw.info['subject_info']['his_id']: subject ID\n",
    "    # - preprocessing: re_referencing + cropping\n",
    "    # - raw.ch_names: ['F3-A2', 'F4-A1', 'C3-A2', 'C4-A1', 'O1-A2', 'O2-A1']\n",
    "    np2raw = tp.np2raw(sub_ID, df_SOL)\n",
    "    np2raw.np2raw(np_all_eeg)\n",
    "    np2raw.re_ref()\n",
    "    raw_re_ref_cropped = np2raw.raw_cropping()\n",
    "\n",
    "    # Automatic Sleep Staging\n",
    "    # - apply ensamble using all six eeg channels\n",
    "    # - automatiaclly saved\n",
    "    #   current directory\n",
    "    #   -- hypnograms\n",
    "    #   -- -- subject_1\n",
    "    #   -- -- subject_2\n",
    "    #   -- -- ...\n",
    "    #   -- -- subject_n\n",
    "    #   -- -- -- predicted_hypnogram.csv\n",
    "    #   -- -- -- probabilistic_hypnogram.csv\n",
    "    automatic_staging = tp.automatic_staging()\n",
    "    automatic_staging.get_hypnos_and_probs(raw_re_ref_cropped.copy())\n",
    "    automatic_staging.ensamble_stagig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "9113688/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "QNAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([])\n",
    "x1 = np.array([1,2,3])\n",
    "x2 = np.array([2,4,6,8,10])\n",
    "\n",
    "# y = np.concatenate((a, x1))\n",
    "x2[:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = np2raw.raw\n",
    "raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_re_ref = np2raw.raw_re_ref\n",
    "raw_re_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_re_ref_cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automatic_staging.raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_re_ref_cropped.copy()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "131b61df41b7a9e44a731ca87c7f9c007eef4be7463370e4edb7a9f329aa519d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('env_yasa')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
